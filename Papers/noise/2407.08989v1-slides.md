# Robustness of LLMs to Perturbations in Text

- Ayush Singh, Navpreet Singh, Shubham Vatsal
- inQbator AI at eviCore Healthcare
- Evernorth Health Services
- Date of Presentation: [Insert Date]

# Introduction

- Clean dataset assumption in NLP systems
- Real-world text often contains errors
- LLMs' robustness to text variations is under-studied
- Importance of evaluating LLMs' robustness to noise

# Background/Related Work

- Previous studies on noise in NLP (Wu et al., 2021)
- Types of noise: human errors, OCR, ASR systems
- Lexical Semantic Change (LSC) detection
- Language Error Correction (LEC) and its evolution

# Contributions

- Systematic evaluation of LLM robustness to text perturbations
- Performance on grammar error correction benchmarks
- Release of human-annotated dataset and code

# Objective

- Evaluate robustness of LLMs to semantic-preserving text corruption
- Measure LLM performance on downstream LSC and LEC tasks
- Hypotheses: LLMs should be robust to text perturbations

# Methodology Overview

- Artificial introduction of noise in datasets
- Measure differences in LLM encodings of clean vs. corrupted text
- Evaluate LLM performance on LSC and LEC tasks

# Datasets

- BEA-19: Essays on various topics by diverse authors
- JFLEG: Annotated fluency corpus from English learners
- IMDB: Subsampled movie reviews with synthetic perturbations

# Model Details

- Models used: GPT-4, LLaMa 3, BERT
- Embedding extraction for similarity measures
- Perturbation techniques: OCR errors, spelling mistakes, etc.

# Experiments

- Single and combined perturbations
- Evaluation metrics: cosine similarity, ERRANT, GLEU
- Annotation tasks for human preference learning

# Results

- GPT-4 showed robustness to text perturbations
- LLaMa's performance varied, indicating sensitivity to sentence length
- GPT-4 achieved state-of-the-art in JFLEG dataset

# Performance Comparisons with Prior Work

- Comparison with supervised and unsupervised LEC models
- GPT-4 outperformed ChatGPT on BEA-19 dataset
- Annotators preferred GPT-4 corrections over human corrections

# Discussion

- Limitations of existing LEC evaluation metrics
- GPT's superior performance due to extensive training data
- LLaMa's issues with short sentences and single-sentence corrections

# Conclusion

- LLMs show robustness to semantic-preserving text perturbations
- GPT-4 demonstrates strong performance in LEC tasks
- Future work: extend LEC to longer texts and improve perturbation methods

# References

- Bryant et al., 2019
- Devlin et al., 2018
- Gulordava and Baroni, 2011
- Srivastava et al., 2020
- Touvron et al., 2023

# Acknowledgements

- Thanking annotators and collaborators
- Funding sources and institutional support

# Q&A

- Invitation for questions
