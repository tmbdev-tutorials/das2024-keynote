# Advancing Machine Learning with OCR2SEQ

- Title: Advancing Machine Learning with OCR2SEQ: An Innovative Approach to Multi-Modal Data Augmentation
- Authors: Michael Lowe, Joseph D. Prusa, Joffrey L. Leevy, Taghi M. Khoshgoftaar
- Institutional Affiliations: Florida Atlantic University
- Date of Presentation: 2024

# Introduction

- Problem Statement: OCR efficacy diminishes in specialized domains with sparse characters and unique vocabulary.
- Motivation: Enhance OCR systems to improve data quality and reliability.
- Scope: Focus on multi-modal generative augmentation strategy to simulate realistic text extraction errors.

# Background/Related Work

- Relevant Previous Work: Techniques like fill-masking, text generation, and text-to-text translation.
- Challenges: Limitations in language perplexity and tokenization impacting OCR effectiveness.
- Key Concepts: Data augmentation, noise correction, sequence de-noising, and transformer architectures.

# Contributions

- Key Contributions: Development of OCR2SEQ framework.
- Novel Techniques: Simulating realistic text extraction errors for better training.
- Impact: Significant improvements in OCR accuracy, particularly in healthcare and library sciences.

# Objective

- Main Objectives: Enhance data quality for sequence-to-sequence models in specialized domains.
- Hypotheses: Augmented data improves the training efficacy and accuracy of text-to-text transformers.

# Methodology Overview

- High-Level Overview: OCR2SEQ framework for generating and using augmented data.
- Data Used: Modified datasets from MIMIC-III and CC News.
- Model Architecture: Sequence-to-sequence language models with noise-tolerant pre-training.

# Datasets

- Description of Datasets: MIMIC-III and CC News datasets.
- Data Sources: Healthcare records and news articles.
- Data Preprocessing: Synthetic augmentation to simulate OCR errors.

# Model Details

- Model Architecture: Autoencoder-based pre-training framework.
- Key Layers and Components: Noise-tolerant design and adaptive document generation.
- Training Procedure: Training on augmented data with simulated errors.

# Experiments

- Experimental Setup: Testing on MIMIC-III and CC News datasets.
- Evaluation Metrics: Character Error Rate (CER) and Word Error Rate (WER).

# Results

- Performance Metrics: Significant reduction in error rates compared to baseline methods.
- Key Findings: OCR2SEQ outperforms other augmentation strategies in generating realistic errors.

# Performance Comparisons with Prior Work

- Comparison with Baselines: OCR2SEQ shows lower CER and WER.
- Performance Gains: Enhanced robustness and accuracy in OCR processes.

# Discussion

- Key Insights: Effective simulation of realistic text extraction errors.
- Interpretation of Results: Improved data quality and model reliability.
- Limitations: Need for further testing across diverse domains.

# Conclusion

- Summary of Contributions: Introduction of OCR2SEQ framework for OCR enhancement.
- Impact of Findings: Improved OCR accuracy and data processing reliability.
- Future Work: Expansion of OCR2SEQ to other fields and refinement of augmentation algorithms.

# References

- Patel C, Patel A, Patel D. Optical character recognition by open source OCR tool tesseract: a case study.
- Smith R. An overview of the tesseract OCR engine.
- Jockers ML, Underwood T. Text-mining the humanities.
- Shorten C, Khoshgoftaar TM, Furht B. Text data augmentation for deep learning.
- Vaswani A, Shazeer N, Parmar N. Attention is all you need.

# Acknowledgements

- Thanks to internal reviewers and supporting institutions.

# Q&A

- Invitation for Questions
