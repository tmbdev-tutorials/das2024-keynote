# Image-based Table Recognition: Data, Model, and Evaluation

- Xu Zhong, Elaheh ShafieiBavani, Antonio Jimeno Yepes
- IBM Research Australia
- Date of Presentation

# Introduction

- Tabular data in documents often contains important information.
- Parsing tables from PDFs and images into structured formats is challenging.
- This paper presents a large dataset and a novel model for table recognition.

# Background/Related Work

- Previous work focuses on table detection, structure recognition, and content recognition.
- Existing datasets and models have limitations in handling diverse table styles.
- Key concepts in deep learning: attention-based encoder-decoder architectures.

# Contributions

- Introduction of PubTabNet, a large-scale dataset with 568k table images.
- Development of an attention-based encoder-dual-decoder (EDD) model.
- Proposal of a new evaluation metric, Tree-Edit-Distance-based Similarity (TEDS).

# Objective

- To facilitate accurate image-based table recognition.
- To outperform existing state-of-the-art methods in table recognition.
- To provide a comprehensive evaluation metric for table recognition.

# Methodology Overview

- PubTabNet dataset: Automatically generated from PMCOA with HTML annotations.
- EDD Model: Combines an encoder, structure decoder, and cell decoder.
- Evaluation using the TEDS metric.

# Datasets

- PubTabNet: 568k table images from scientific articles in PMCOA.
- Comparison with existing datasets like SciTSR, Table2Latex, and TIES.
- Data preprocessing: Filtering erroneous bounding boxes and rare tables.

# Model Details

## EDD Model Architecture

- Encoder: Convolutional Neural Network (CNN) to capture visual features.
- Structure Decoder: Recognizes table structure.
- Cell Decoder: Recognizes cell content, triggered by the structure decoder.
- Both decoders use attention mechanisms.

## Training Procedure

- Pre-train the encoder and structure decoder.
- Train the entire EDD network with cross-entropy loss for structural and cell tokens.
- Use beam search during inference.

# Experiments

- Comparison with five off-the-shelf tools and the WYGIWYS model.
- Evaluation on both simple and complex tables from PubTabNet.
- Quantitative analysis shows EDD outperforms baselines by a significant margin.

# Results

- EDD achieves an average TEDS score of 88.3%.
- Substantial improvement over existing tools and models.
- Demonstrates robustness in recognizing complex table structures.

# Performance Comparisons with Prior Work

- EDD outperforms Tabula, Traprange, Camelot, PDFPlumber, and Adobe Acrobat Pro.
- Comparison with WYGIWYS shows a 9.7% improvement in TEDS score.

# Ablation Studies

- Analysis of the impact of table size on model performance.
- Evaluation of different configurations of the encoder's last CNN layer.
- Demonstration of the generalizability of EDD on synthetic datasets.

# Visualizations

- Attention distribution of structure and cell decoders on example tables.
- Comparison of recognized tables by EDD and baseline methods.
- Performance metrics across different table sizes.

# Discussion

- EDD's dual-decoder approach effectively separates structure and content recognition.
- TEDS metric provides a comprehensive evaluation of table recognition performance.
- Limitations: Current dataset lacks cell coordinates.

# Conclusion

- Introduction of PubTabNet and EDD model for image-based table recognition.
- EDD demonstrates superior performance on complex tables.
- Future work: Adding cell coordinates to PubTabNet and integrating table detection.

# References

- Key citations on table recognition, datasets, and deep learning models.
- References for the TEDS metric and related evaluation methods.

# Acknowledgements

- Acknowledgment of contributors and funding sources.

# Q&A

- Invitation for questions and discussion.
