# ONE SENTENCE SUMMARY:

GVdoc, a graph-based visual document classification model, outperforms state-of-the-art models on out-of-distribution data by leveraging document layout and spatial relationships.

# MAIN POINTS:

1. Robust models must perform well on unseen and out-of-domain data.
2. Visual document classifiers struggle with out-of-distribution examples.
3. Image-based classifiers lack text components; transformer models face token serialization issues.
4. GVdoc creates document graphs using layouts and trains a graph neural network.
5. GVdoc outperforms state-of-the-art models on out-of-distribution data.
6. Document AI models often fail on out-of-distribution data due to fixed training distributions.
7. Previous methods use large models with high computational demands.
8. GVdoc uses graph-based modeling to leverage reading order and spatial layout.
9. GVdoc maintains performance with fewer parameters and better generalization.
10. GVdoc’s graph-based approach combines both β skeleton and paragraph-level graphs.

# TAKEAWAYS:

1. GVdoc effectively addresses out-of-distribution challenges in visual document classification.
2. The model uses a graph neural network to learn from document layouts and relationships.
3. GVdoc achieves better generalization with fewer parameters compared to other models.
4. Combining β skeleton and paragraph-level graphs enhances GVdoc's performance.
5. GVdoc demonstrates robustness and accuracy across various document classification tasks.
