# Nougat: Neural Optical Understanding for Academic Documents
- Lukas Blecher, Guillem Cucurull, Thomas Scialom, Robert Stojnic
- Meta AI

# Introduction
- Scientific knowledge predominantly stored in PDFs
- PDFs cause loss of semantic information, especially for mathematical expressions
- Propose Nougat, a Visual Transformer model for OCR tasks
- Converts scientific documents into markup language
- Enhances accessibility of scientific knowledge

# Background/Related Work
- Existing OCR engines like Tesseract OCR excel in character detection but fail in semantic understanding
- Mathematical expressions lose semantic meaning in line-by-line OCR approaches
- Related works: Grammar-based methods, encoder-decoder models, and Transformer architectures in OCR
- Previous solutions like GROBID and pdf2htmlEX lack semantic recovery for mathematical expressions

# Contributions
- Release of pre-trained model for converting PDFs to markup language
- Introduction of a pipeline to create datasets pairing PDFs with source code
- Model operates solely on document images, suitable for scanned papers and books

# Objective
- Main objective: Convert images of document pages to formatted markup text
- Hypothesis: Transformer-based model can enhance OCR for scientific documents

# Methodology Overview
- Encoder-decoder Transformer architecture
- Uses a Swin Transformer encoder for document images
- Decoder generates a sequence of tokens auto-regressively

# Model Details
## Encoder
- Visual encoder processes document image, crops margins, resizes, and pads to fixed size
- Uses Swin Transformer for hierarchical vision processing
- Outputs a sequence of embedded patches

## Decoder
- Decodes embedded patches into tokens using Transformer decoder with cross-attention
- Uses mBART decoder implementation specialized in scientific text

# Data Augmentation
- Employs various image augmentations: erosion, dilation, noise, blur, compression
- Augmentations simulate imperfections in scanned documents
- Perturbations added to ground truth text to reduce repetitive loops

# Datasets
- Created dataset from arXiv, PubMed Central (PMC), and Industry Documents Library (IDL)
- arXiv: 1.7M articles processed into HTML and then markup
- PMC: Fewer articles due to less rich semantic information in XML
- IDL: High-quality OCR text used for pre-training

# Experiments
- Document images rendered at 96 DPI
- Model initialized with pre-trained weights
- Training with AdamW optimizer, batch size of 192, learning rate adjustments

# Results
- Metrics: Edit distance, BLEU, METEOR, F1-score
- Comparisons with GROBID and LaTeX OCR
- Nougat models outperform other approaches, especially in plain text and mathematical expressions

# Performance Comparisons with Prior Work
- Nougat models achieve higher scores in all metrics compared to GROBID and embedded PDF text
- Smaller Nougat model performs on par with the larger base model

# Repetitions During Inference
- Model sometimes degenerates into repeating loops
- Anti-repetition augmentation introduced during training
- Repetition detection heuristic implemented during inference

# Limitations & Future Work
- Repetition issue needs further addressing
- Model trained on English documents; performance on other languages varies
- Future work: Improve consistency across document pages, reduce repetition loops

# Conclusion
- Nougat presents a novel end-to-end OCR model for scientific documents
- Enhances accessibility by converting PDFs to markup
- Code and models released to support further research

# References
- Key citations including works on OCR, mathematical expression recognition, and Transformer architectures

# Acknowledgements
- Thanks to Ross Taylor, Marcin Kardas, Iliyan Zarov, and others for valuable discussions and support

# Q&A
- Invitation for questions
