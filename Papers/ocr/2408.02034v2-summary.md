# ONE SENTENCE SUMMARY:
Mini-Monkey introduces a multi-scale adaptive cropping strategy and scale compression mechanism to enhance lightweight multimodal large language models' high-resolution image processing capabilities.

# MAIN POINTS:
1. Mini-Monkey tackles object segmentation issues in MLLMs caused by traditional cropping methods.
2. It employs a multi-scale adaptive cropping strategy (MSAC) to generate non-segmented object representations.
3. MSAC adaptively selects different aspect ratios to prevent semantic incoherence.
4. A Scale Compression Mechanism (SCM) is used to reduce computational overhead.
5. Mini-Monkey achieves state-of-the-art performance among 2B-parameter MLLMs.
6. Outperforms 8B-parameter models on OCRBench with a score of 802.
7. Efficient training using only eight RTX 3090 GPUs.
8. Demonstrates superior performance on both general multimodal and document understanding tasks.
9. Combines features from different scales within the LLM for enhanced understanding.
10. Code is available at https://github.com/Yuliang-Liu/Monkey.

# TAKEAWAYS:
1. Mini-Monkey significantly improves lightweight MLLMs' high-resolution image processing.
2. MSAC prevents semantic incoherence by adaptive multi-scale cropping.
3. SCM effectively reduces computational demands without additional parameters.
4. Mini-Monkey sets new benchmarks in various multimodal and document understanding tasks.
5. The model is highly efficient and easily trainable with limited hardware resources.
