# Title Slide
- Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text
- Zhun Yang, Adam Ishay, Joohyung Lee
- Arizona State University, Samsung Research
- July 9-14, 2023

# Introduction
- Problem: LLMs like GPT-3 are not on par with specialized models for natural language reasoning tasks
- Motivation: Enhance LLMs' reasoning by integrating logic programming
- Scope: Combining LLMs with Answer Set Programs (ASP) for multiple QA tasks without retraining

# Background/Related Work
- Previous Work: LLMs for general reasoning, plan generation, and semantic parsing
- Limitations: Shallow reasoning, lack of deep understanding in concepts like logic and probability
- Key Concepts: Answer Set Programming (ASP) for declarative knowledge representation

# Contributions
- Key Contributions: Dual-process neuro-symbolic reasoning framework combining LLMs and ASP
- Novel Techniques: Using LLMs as few-shot semantic parsers to generate logical forms for ASP
- Impact: State-of-the-art performance on several NLP benchmarks and robot planning tasks

# Objective
- Main Objective: Enhance reasoning capabilities of LLMs using logic programming
- Research Questions: Can LLMs serve as effective semantic parsers for ASP? Can this combination improve performance on various QA tasks?

# Methodology Overview
- Approach: LLMs convert natural language into logical forms; ASP handles reasoning
- Data: Examples from benchmarks like bAbI, StepGame, CLUTRR, and gSCAN
- Model: Dual-system combining LLMs with reusable ASP knowledge modules

# Datasets
- bAbI: 20 QA tasks testing various reasoning problems
- StepGame: Contextual QA with multi-hop spatial reasoning
- CLUTRR: Inferring family relationships from narratives
- gSCAN: Action sequence execution in a grid-based environment

# Model Details
- Model Architecture: LLMs for semantic parsing, ASP for reasoning
- Key Components: Few-shot prompts for LLMs, ASP knowledge modules
- Training: No extensive training required, few examples sufficient for LLM adaptation

# Experiments
- Setup: Evaluated on bAbI, StepGame, CLUTRR, and gSCAN datasets
- Metrics: Accuracy compared to state-of-the-art models

# Results
- Performance Metrics: Achieved state-of-the-art results on all tested datasets
- Key Findings: High accuracy and transparency in results, easy error identification

# Performance Comparisons with Prior Work
- Baselines: Compared with STM, QRN, RN, RRN, UT, SynSup, DeepProbLog
- State-of-the-Art Models: Outperformed existing models in most benchmarks
- Gains: Significant improvement in reasoning tasks without retraining

# Ablation Studies
- Effect of Components: LLMs as semantic parsers, ASP for reasoning
- Model Variants: Different versions of GPT-3 evaluated (text-curie-001, text-davinci-002, text-davinci-003)

# Visualizations
- Model Outputs: Examples of predictions and reasoning steps
- Accuracy Curves: Performance comparison across different datasets
- Plots: Error analysis and correction visualization

# Discussion
- Insights: LLMs excel in semantic parsing, ASP provides robust reasoning
- Interpretation: Combining LLMs and ASP leverages strengths of both approaches
- Limitations: Dependence on accurate semantic parsing by LLMs

# Conclusion
- Summary: Dual-process model combining LLMs with ASP achieves high accuracy in reasoning tasks
- Impact: Demonstrates general applicability and robustness across multiple QA tasks
- Future Work: Explore automated generation of logic rules using LLMs, expand knowledge modules

# References
- Lifschitz, V. (2008). What is answer set programming? Communications of the ACM.
- Weston, J., Bordes, A., Chopra, S., & Mikolov, T. (2016). Towards ai-complete question answering: A set of prerequisite toy tasks.
- Nye, M., Tessler, M., Tenenbaum, J., & Lake, B. (2021). Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning.

# Acknowledgements
- Supported by National Science Foundation Grant IIS-2006747

# Q&A
- Invitation for Questions
