# ONE SENTENCE SUMMARY:
Coupling large language models with logic programming enhances robust and general reasoning for multiple NLP benchmarks and robot planning tasks.

# MAIN POINTS:
1. LLMs like GPT-3 are robust but lack deep reasoning abilities.
2. LLMs can serve as effective few-shot semantic parsers.
3. LLMs convert natural language into logical forms for logic-based reasoning.
4. Answer set programs (ASP) provide declarative and interpretable reasoning.
5. Combining LLMs with ASP handles multiple QA tasks without retraining.
6. The method achieves state-of-the-art performance on bAbI, StepGame, CLUTRR, and gSCAN benchmarks.
7. Successfully tackles robot planning tasks LLMs alone fail to solve.
8. Few-shot examples guide LLM adaptation to specific tasks.
9. ASP knowledge modules are reusable across different tasks.
10. The method helps identify and correct errors in datasets.

# TAKEAWAYS:
1. LLMs excel at converting diverse expressions into canonical forms for logical reasoning.
2. Combining LLMs with ASP enables robust and general reasoning without extensive retraining.
3. The modular design allows easy error identification and improvement.
4. The method can validate and correct errors in datasets.
5. High accuracy and transparency make it useful for data validation and interpretation.
