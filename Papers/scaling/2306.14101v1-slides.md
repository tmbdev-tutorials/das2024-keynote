# Language Models are Weak Learners

- Hariharan Manikandan, Yiding Jiang, J Zico Kolter
- Carnegie Mellon University, Bosch Center for AI
- {hmanikan, yidingji, zkolter}@cs.cmu.edu
- Date: [Date of Presentation]

# Introduction

- Weak learners: classifiers achieving better-than-random performance
- Boosting: ensemble of weak learners for strong classification
- Large Language Models (LLMs) in natural language tasks
- Can LLMs serve as weak learners in boosting for tabular data?

# Background/Related Work

- Tabular data: challenges in deep learning due to lack of inherent structure
- Recent interest in deep learning for tabular tasks (e.g., data integration, classification)
- Prompting LLMs: zero-shot, few-shot learning via context strings
- Boosting algorithms: AdaBoost, Gradient Boosting, Stochastic Gradient Boosting

# Contributions

- LLMs as weak learners in a boosting framework for tabular data
- Conversion of tabular data to text for LLMs
- Integration of LLM-generated weak learners into boosting
- Outperformance of traditional methods in certain settings

# Objective

- Main Objective: Evaluate LLMs as weak learners in boosting for tabular data
- Research Questions: 
  - Can LLMs effectively summarize tabular data for classification?
  - How does the boosting framework with LLMs perform compared to traditional methods?

# Methodology Overview

- Approach: Use LLMs to generate summaries of tabular data as weak learners
- Data Conversion: Convert tabular data to natural language descriptions
- Boosting: Integrate LLM-generated summaries into a boosting algorithm

# Datasets

- 18 tabular datasets from UCI and OpenML
- Examples: caesarian, iris, wine, diabetes
- Data Types: continuous and discrete attributes
- Data Split: 50/10/40 for train, validation, and test sets

# Model Details

- Data Conversion: Zero-shot prompting with metadata and textual representation
- Summarization: Generate summaries using LLMs (e.g., "tldr" prompt)
- Boosting: Use AdaBoost algorithm with LLM-generated weak learners
- Sampling: Weighted stratified sampling with clustering

# Experiments

- Methods Compared: Zero-shot, Few-shot, Summary, Summary Boosting
- Baselines: KNN, LIFT, TabPFN, XGBoost
- Evaluation Metrics: Test error rates on various datasets

# Results

- Summary Boosting outperforms zero-shot and few-shot learning
- Consistent improvement with summarization over few-shot
- Superior performance of boosting with LLMs in small datasets
- Challenges in continuous attribute reasoning without finetuning

# Performance Comparisons with Prior Work

- Comparison with few-shot and zero-shot prompting
- Summary Boosting vs. traditional methods: LIFT, XGBoost
- Performance gains in small datasets using LLM prior knowledge

# Visualizations

- Ablation studies on summarization techniques
- Effects of different continuous attribute encoding methods
- Comparison of LLM sizes and prompting strategies

# Discussion

- Insights: LLMs can serve as effective weak learners with summarization
- Interpretation: Summarization leverages LLM's prior knowledge
- Limitations: Challenges in continuous attribute reasoning, API costs

# Conclusion

- Summary: LLMs as weak learners in boosting frameworks for tabular data
- Impact: New paradigm for integrating LLMs in machine learning pipelines
- Future Work: Explore more powerful LLMs, structured prompting techniques

# References

- Schapire, R. E. (1990). The strength of weak learnability.
- Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting.
- Brown, T. et al. (2020). Language models are few-shot learners.
- Vaswani, A. et al. (2017). Attention is all you need.

# Acknowledgements

- Funding from Bosch Center of Artificial Intelligence

# Q&A

- Invitation for Questions
