# Title Slide

- Can Language Models Pretend Solvers? Logic Code Simulation with LLMs
- Minyu Chen, Guoqiang Li, Ling-I Wu, Ruibang Liu, Yuxin Su, Xi Chang, Jianxin Xue
- Shanghai Jiao Tong University, Shanghai Polytechnic University
- Date of Presentation

# Introduction

- Problem Statement: Investigating the role of LLMs as logic code interpreters and executors
- Motivation: Limited attention on LLMs' ability to simulate logical solvers in predicting logic program results
- Scope of the Paper: Focuses on logic code simulation using LLMs and introduces the Dual Chains of Logic (DCoL) technique

# Background/Related Work

- Logical solvers like Z3 and cvc5 are widely used in software engineering
- Existing research mostly views LLMs as natural language logic solvers or translators
- LLMs have shown potential in code generation, documentation, and understanding

# Contributions

- Introduced a novel task: logic code simulation
- Collected three new datasets for logic code simulation
- Proposed the Dual Chains of Logic (DCoL) technique, improving accuracy by 7.06% with GPT-4-Turbo

# Objective

- Main Objectives: Assess LLMs' capability to simulate logic codes and identify strengths and pitfalls
- Research Questions: Can LLMs efficiently simulate logic codes? What strengths and pitfalls arise?

# Methodology Overview

- High-Level Overview: Evaluate LLMs on curated datasets and propose DCoL for better performance
- Data Used: Three novel datasets tailored for logic code simulation
- Model Architecture: Transformer-based LLMs such as GPT-3.5 Turbo, GPT-4 Turbo, LLaMA-2, and Code LLaMA

# Datasets

- ProntoQA: Propositional-logic QA dataset translated into logic form
- Z3Tutorial: Collected from Z3 programming tutorials
- Z3Test: Extracted from the Z3 official repository with categorized question types

| Dataset     | Formulation | Format | # of Samples | Mean LoC |
|-------------|-------------|--------|--------------|----------|
| ProntoQA    | PL          | NL     | 500          | -        |
| Z3Tutorial  | SMT         | Z3Py   | 37           | 9.90     |
| Z3Test      | SMT         | Z3Py   | 85           | 8.37     |
| SMTSIM      | SMT         | SMTLIB | 104          | 14.36    |

# Model Details

- Model Architecture: Transformer-based LLMs
- Key Layers and Components: Decoder-only networks, pre-training on extensive text data
- Training Procedure: Unsupervised training, supervised fine-tuning, reinforcement learning from human feedback

# Experiments

- Experimental Setup: Evaluate LLMs on logic code simulation tasks using various prompting methods
- Evaluation Metrics: Accuracy, Unknown rate, Execution accuracy

# Results

- Performance Metrics: Accuracy improvement with DCoL, higher execution accuracy with GPT models
- Key Findings: DCoL enhances LLM performance, GPT models show better resilience compared to LLaMA

# Performance Comparisons with Prior Work

- Comparison with Baselines: Standard prompting, COT, Plan-and-Solve, and CoSm methods
- Performance Gains: DCoL shows steady improvement across datasets, especially with GPT models

# Discussion

- Key Insights: LLMs can effectively simulate logic solvers, DCoL provides significant performance boost
- Interpretation of Results: LLMs show potential in logic reasoning and code simulation
- Limitations: Struggles with complex datasets, certain error types remain challenging

# Conclusion

- Summary of Contributions: Proposed logic code simulation task, collected new datasets, introduced DCoL technique
- Impact of Findings: Demonstrated LLMs' capability in logic code simulation
- Future Work Directions: Enhance DCoL, apply to broader logic code scenarios, integrate with natural language to logic code conversion research

# References

- Key Citations: 
  - De Moura and Bj√∏rner, "Z3: An efficient smt solver," 2008
  - Tafjord, Dalvi, and Clark, "Proofwriter: Generating implications, proofs, and abductive statements over natural language," 2021
  - Wei et al., "Chain-of-thought prompting elicits reasoning in large language models," 2022

# Acknowledgements

- Acknowledgements to contributors and institutions supporting this research

# Q&A

- Invitation for Questions
