# CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering
- Nirmalie Wiratunga, Ramitha Abeyratne, Lasal Jayawardena, Kyle Martin, Stewart Massie, Ikechukwu Nkisi-Orji, Ruvan Weerasinghe, Anne Liret, Bruno Fleisch
- Robert Gordon University, Informatics Institute of Technology, BT France
- Date of Presentation: 2024

# Introduction
- Problem Statement: Enhancing LLM output by integrating prior knowledge.
- Motivation: Improve knowledge-intensive tasks like legal question-answering.
- Scope of the Paper: Introducing CBR-RAG to augment LLM queries with contextually relevant cases.

# Background/Related Work
- CBR has a long history in the legal domain, focusing on feature extraction and case indexing.
- LLMs like GPT and BERT are used for LegalAI but face challenges like hallucination and factual faithfulness.
- RAG systems present factual data to LLMs, but current methods do not utilize CBR's potential.

# Contributions
- Formalize the role of CBR methodology in RAG systems.
- Empirical comparison of different retrieval methods for RAG.
- Application of CBR-RAG in the legal domain with results for a generative legal QA application.

# Objective
- Main Objective: Enhance LLM outputs by integrating CBR with RAG.
- Hypothesis: Context from CBR's case reuse will improve the quality of generated answers.

# Methodology Overview
- High-Level Overview: Integrate CBR's initial retrieval stage with RAG to provide contextually enriched prompts.
- Data Used: Australian Open Legal QA dataset.
- Model Architecture: Dual-embedding approach using intra and inter embeddings.

# Datasets
- Description of Datasets: Australian Open Legal QA dataset with 2,124 LLM-generated question-answer pairs.
- Data Sources: Australian Open Legal Corpus.
- Data Preprocessing Steps: Extract entities and legal acts, create embeddings using BERT, LegalBERT, and AnglEBERT.

# Model Details
- Model Architecture: Dual-embedding case representation with intra and inter embeddings.
- Key Layers and Components: BERT, LegalBERT, AnglEBERT embeddings.
- Training Procedure: Contrastive learning for AnglEBERT, standard MLM and NSP for BERT and LegalBERT.

# Experiments
- Experimental Setup: Compare retrieval methods using different embeddings and weights.
- Evaluation Metrics: F1-score for retrieval and cosine similarity for generated answers.

# Results
- Performance Metrics: Hybrid AnglEBERT with k=3 showed the best performance.
- Key Findings: CBR-RAG systems lead to significant improvements in answer quality.

# Performance Comparisons with Prior Work
- Comparison with Baselines: All hybrid variants outperformed No-RAG baseline.
- Comparison with State-of-the-Art Models: Hybrid AnglEBERT showed higher semantic similarity.
- Performance Gains or Trade-offs: Hybrid embeddings provided fine-grained similarity comparison.

# Discussion
- Key Insights: Selecting an appropriate embedding for case representation is crucial.
- Interpretation of Results: AnglEBERT's contrastive approach to embedding optimization is highly effective.
- Limitations: Current embeddings not fine-tuned to the specific legal corpus.

# Conclusion
- Summary of Contributions: Introduced CBR-RAG, demonstrated its effectiveness in legal QA.
- Impact of Findings: Improved LLM outputs for knowledge-reliant tasks.
- Future Work Directions: Explore alternative text embeddings, fine-tuning strategies, and case aggregation methods.

# References
- Devlin, J., Chang, M.W., Lee, K., Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding.
- Lewis, P., et al. (2020). Retrieval-augmented generation for knowledge-intensive NLP tasks.
- Chalkidis, I., et al. (2020). Legal-BERT: The muppets straight out of law school.
- Li, X., Li, J. (2023). Angle-optimized text embeddings.
- Rissland, E.L., Daniels, J.J. (1995). A hybrid CBR-IR approach to legal information retrieval.

# Acknowledgements
- Funded by SFC International Science Partnerships Fund.

# Q&A
- Invitation for Questions
