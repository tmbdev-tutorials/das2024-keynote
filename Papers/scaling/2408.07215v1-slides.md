# Can Large Language Models Reason? A Characterization via 3-SAT

- Rishi Hazra, Gabriele Venturato, Pedro Zuidberg Dos Martires, Luc De Raedt
- Centre for Applied Autonomous Sensor Systems (AASS), Örebro University, Sweden
- Department of Computer Science, KU Leuven, Belgium
- Date of Presentation

# Introduction

- Investigate reasoning abilities of Large Language Models (LLMs)
- Use 3-SAT, a prototypical NP-complete problem
- Examine LLMs' performance across varying problem hardness
- Show LLMs' limitations in true reasoning required for solving 3-SAT problems

# Background/Related Work

- LLMs have shown capabilities in zero-shot reasoning, planning, theorem proving
- Critical views highlight LLMs' limitations in logical reasoning, planning, and self-evaluation
- Concerns about dataset contamination inflating performance
- Theoretical limitations of transformer layers in function composition and logical reasoning

# Contributions

- Characterize LLMs' reasoning abilities using 3-SAT phase transitions
- Empirical evidence showing LLMs' limitations in true reasoning
- Differentiate between statistical feature exploitation and true reasoning

# Objective

- Assess reasoning capabilities of LLMs using 3-SAT phase transitions
- Analyze LLMs' performance across varying problem hardness
- Determine if LLMs can perform true reasoning or rely on statistical features

# Methodology Overview

- Reframe 3-SAT problem as a natural language task (SAT-Menu)
- Use GPT-4 Turbo as the reference LLM
- Analyze performance on 3-SAT Decision and 3-SAT Search problems
- Compare with other state-of-the-art LLMs

# Datasets

- Generated dataset with k = 3 for NP-complete problems (3-SAT)
- Used α = m/n to guide dataset generation
- Dataset includes both satisfiable (SAT) and unsatisfiable (unSAT) instances
- Annotated with model count for each formula

# Model Details

## SAT-Menu Setup

- Input: Preferences of individuals (likes and dislikes)
- Task: Output orderable and non-orderable food items satisfying all preferences
- Example prompt and solution provided for context

## SAT-CNF Setup

- Input: List of clauses in CNF format
- Task: Find a valuation of Boolean variables satisfying the formula
- Example prompt and solution provided for context

# Experiments

- Evaluate GPT-4's accuracy across formulas with varying α
- Analyze performance in easy, hard, and over-constrained regions
- Compare with other LLMs and LLM-Modulo frameworks

# Results

## Can LLMs solve 3-SAT problems?

- GPT-4 shows competence in easy regions, accuracy drops in hard region
- SAT Search poses a greater challenge than SAT Decision
- Performance dependence on satisfiability ratio observed

## Can LLM-Modulo frameworks boost performance?

- LLMs augmented with external solvers show significant accuracy improvement
- SAT-Translate approach achieves near-perfect accuracy across α range
- Translating 3-SAT formulas is computationally less complex than solving them

# Discussion

- LLMs' apparent reasoning capabilities in easy regions are due to statistical features
- In hard regions, performance drops due to inability to reason according to defined criteria
- Fine-grained empirical study complements theoretical results on LLM reasoning capabilities

# Conclusion

- LLMs predominantly exploit statistical features, not true reasoning capabilities
- LLMs effective in translating problems to formal language for solvers
- Future work: Enhance LLMs' reasoning capabilities and integration with symbolic systems

# References

- Davis, E., Marcus, G. (2015). Commonsense reasoning and commonsense knowledge in artificial intelligence.
- Genesereth, M.R., Nilsson, N.J. (1987). Logical Foundations of Artificial Intelligence.
- Bottou, L. (2014). From machine learning to machine reasoning: An essay.
- Russell, S., Norvig, P. (2010). Artificial Intelligence: A Modern Approach, 3rd edn.
- Kojima, T. et al. (2022). Large language models are zero-shot reasoners.

# Acknowledgements

- Holger Hoos, Heikki Mannila, Paolo Frasconi, Pascal Van Hentenryck, Ross King, Giuseppe Marra, Pieter Delobelle, Hendrik Blockeel
- Funding from Wallenberg AI Autonomous Systems and Software Program (WASP), EU H2020 ICT48 project “TAILOR”, KU Leuven Research Fund

# Q&A

- Invitation for Questions
