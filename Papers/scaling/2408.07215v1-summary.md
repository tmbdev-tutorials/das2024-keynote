# ONE SENTENCE SUMMARY:
Large Language Models (LLMs) exhibit limited true reasoning capabilities, struggling significantly with complex 3-SAT problems, especially in hard regions.

# MAIN POINTS:
1. LLMs often bypass true reasoning using shortcuts.
2. Standard benchmarks may inflate LLMs' reasoning performance.
3. 3-SAT is used to empirically assess LLMs' reasoning abilities.
4. Reasoning abilities vary with problem difficulty.
5. LLMs perform well in easy regions but poorly in hard regions.
6. Phase transitions in 3-SAT highlight reasoning challenges.
7. GPT-4's performance drops to â‰ˆ 10% in hard regions for SAT Search.
8. Augmenting LLMs with external solvers boosts performance.
9. LLMs can translate problems into formal languages for solvers.
10. Current LLMs predominantly exploit statistical features rather than true reasoning.

# TAKEAWAYS:
1. LLMs struggle with true reasoning, especially in complex problem regions.
2. GPT-4 shows significant performance drop in hard 3-SAT problems.
3. External solvers significantly enhance LLMs' problem-solving accuracy.
4. LLMs' reasoning capabilities are often a mirage, relying on statistical features.
5. Real-world LLM applications benefit from combining LLMs with symbolic solvers.
