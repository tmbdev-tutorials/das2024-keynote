# ONE SENTENCE SUMMARY:
The "Performance Law" offers an empirical method to predict the MMLU scores of large language models (LLMs) based on key hyperparameters and training data size, enhancing model development efficiency.

# MAIN POINTS:
1. Performance Law predicts MMLU scores of LLMs using model hyperparameters and training data size.
2. Key hyperparameters include layers, hidden size, FFN size, and training tokens.
3. Empirical model saturation clip limits effective training tokens.
4. Model instability discount accounts for training precision issues.
5. Performance Law generalizes across different model types and sizes.
6. MoE models require additional consideration of activated parameters.
7. Accurate predictions demonstrated using 10 open-source models.
8. Performance Law aids in choosing efficient LLM architectures.
9. Helps monitor model health and predict potential upscaling.
10. Accounts for data quality, distribution, and contamination risks.

# TAKEAWAYS:
1. Performance Law enables accurate performance predictions of LLMs, saving computational resources.
2. Model depth positively impacts performance but increases instability risks.
3. Larger hidden sizes are often more effective than larger FFN sizes.
4. MoE models show promise but are challenging to train.
5. Ensuring data quality and addressing contamination are crucial for accurate model performance.
