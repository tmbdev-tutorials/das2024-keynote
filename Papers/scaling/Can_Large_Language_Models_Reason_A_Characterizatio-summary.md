## ONE SENTENCE SUMMARY:
Large Language Models (LLMs) struggle with true reasoning, particularly in solving 3-SAT problems, often relying on statistical shortcuts instead.

## MAIN POINTS:
1. LLMs possess purported reasoning abilities, but often use statistical shortcuts.
2. Current benchmarks may be overrepresented in LLM training data, skewing results.
3. 3-SAT problems are used to characterize LLM reasoning abilities.
4. Empirical evidence shows LLMs fail at true reasoning required for 3-SAT.
5. LLMs perform well on easy 3-SAT problems but fail in hard regions.
6. LLM-Modulo frameworks can boost performance by integrating external solvers.
7. GPT-4 outperforms other models but still struggles with hard 3-SAT regions.
8. Phase transitions in 3-SAT highlight LLM limitations in reasoning.
9. LLMs are effective at translating problems into formal languages for solvers.
10. Theoretical findings suggest LLM computations are too restrictive for logical reasoning tasks.

## TAKEAWAYS:
1. LLMs often rely on statistical features rather than true reasoning.
2. Benchmark contamination can inflate LLM reasoning performance.
3. 3-SAT problems highlight the limitations of LLMs in logical reasoning.
4. External solvers significantly enhance LLM performance.
5. GPT-4 shows the best performance among state-of-the-art LLMs but still has notable limitations.
