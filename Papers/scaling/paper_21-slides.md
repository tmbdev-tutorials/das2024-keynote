# LLM Reliability and CBR: How Case Based Reasoning Can Improve the Performance of Large Language Models

- Kaitlynne Wilkerson
- Luddy School of Informatics, Computing, and Engineering, Indiana University
- Date of Presentation: July 1, 2024

# Introduction

- Problem: LLMs make factual errors and hallucinate
- Motivation: Improve accuracy, interpretability, and explainability of LLMs
- Scope: Leveraging Case Based Reasoning (CBR) to enhance LLM performance

# Background/Related Work

- AI failures can cause unpredictable or dangerous behavior
- ChatGPT has spotlighted the capabilities and risks of LLMs
- Trust in AI systems is crucial for user acceptance

# Contributions

- Integration of CBR with LLMs to improve accuracy
- Enhancing interpretability and explainability through case-based methods
- Establishing cases as a knowledge source for LLM improvement

# Objective

- Improve LLM accuracy and interpretability
- Make LLM reasoning processes more explainable
- Explore how CBR can mitigate LLM limitations

# Methodology Overview

- Use of ChatGPT 3.5 and Llama 2 for experiments
- Case-based augmentation of LLM prompts
- Evaluation through human subjects and performance metrics

# Datasets

- Triage classification dataset from Kaggle
- Preprocessing to remove instances with missing values
- Random selection for training and test sets

# Model Details

- Use of k-NN retrieval for case selection
- Prompt construction through extensive pre-testing
- Evaluation of LLM performance with and without case augmentation

# Experiments

- Human subjects study on trust and case presentation
- Comparison of LLM accuracy with case-based prompts
- Analysis of LLM behavior under different conditions

# Results

- Cases improve LLM accuracy over baseline prompts
- Nearest Neighbor cases elicit higher user trust
- Differences in LLM capabilities affect case-based performance

# Conclusion

- Case integration can enhance LLM performance and trust
- Future work includes testing across multiple domains and conditions
- User trust evaluation under varied scenarios

# References

- Amershi, S., et al. (2019). Guidelines for human-AI interaction.
- Sundar, S. S. (2020). Rise of machine agency.
- Jacovi, A., et al. (2021). Formalizing trust in artificial intelligence.
- Gates, L., et al. (2023). Cases are king: A user study of case presentation to explain CBR decisions.
- Wilkerson, K., Leake, D. (in press). On implementing case-based reasoning with large language models.

# Acknowledgements

- Funded by the US Department of Defense
- Supported by Lilly Endowment, Inc. through Indiana University Pervasive Technology Institute

# Q&A

- Invitation for Questions
