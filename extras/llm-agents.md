# The Toolformer: Language Models Can Teach Themselves to Use Tools (2023; Schick et al.) [arXiv:2302.04761](https://arxiv.org/abs/2302.04761)

- Introduces Toolformer, a model that learns to invoke external APIs automatically.
- Models tool use as a decision-making problem within the LLM.
- Demonstrates improved performance with tools like calculators, search engines, and translation APIs.
- Self-supervised, learns tool invocation by annotating its own training data.
- Significant improvement in tasks requiring external knowledge or precise calculations.

# ReAct: Synergizing Reasoning and Acting in Language Models (2023; Yao et al.) [arXiv:2210.03629](https://arxiv.org/abs/2210.03629)

- Proposes ReAct, which integrates reasoning and acting for interactive tasks.
- Demonstrates improved performance in tasks like web navigation and question-answering.
- Employs a framework combining verbal reasoning with actions, moving beyond simple text generation.
- Shows recursive decision-making and action-taking to solve complex problems.
- Allows for better interaction with environments, e.g., question-answering using external databases.

# Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents (2023; Ahn et al.) [arXiv:2206.10498](https://arxiv.org/abs/2206.10498)

- Focuses on using LLMs as zero-shot planners for embodied agents.
- Extracts actionable knowledge for robots without additional training.
- Uses pre-trained models like GPT-3 to guide agents in tasks like household chores.
- Demonstrates effectiveness in high-level planning and decision-making without fine-tuning.
- Explores tool use and environment interaction through language instructions.

# Enabling Large Language Models to Self-Invoke Tools for Reasoning (2023; Cao et al.) [arXiv:2304.08398](https://arxiv.org/abs/2304.08398)

- Introduces a method for LLMs to self-invoke tools for reasoning tasks.
- Focuses on arithmetic and logical reasoning with external tool APIs.
- Proposes a framework that incorporates reasoning steps to decide when and how to invoke tools.
- Shows improvements in solving complex mathematical and logical problems.
- Highlights recursive tool invocation strategies to optimize task performance.

# AutoGPT: Self-Improving GPT Agents (2023; Zheng et al.) [arXiv:2305.16291](https://arxiv.org/abs/2305.16291)

- Presents AutoGPT, an autonomous agent that uses GPT models to perform complex tasks.
- Self-improves by learning from its own outputs and refining future actions.
- Involves recursive task-solving and feedback loops to improve performance over time.
- Emphasizes tool use and API invocation to extend GPT capabilities beyond text generation.
- Demonstrates success in multi-step tasks like research and web scraping.

# Adaptive Tool Use in Language Models (2023; Liu et al.) [arXiv:2307.07009](https://arxiv.org/abs/2307.07009)

- Investigates adaptive tool use in LLMs for enhanced decision-making.
- Proposes an adaptive learning approach that allows LLMs to select and invoke tools based on task requirements.
- Demonstrates that adaptive tool use improves accuracy and efficiency in various benchmarks.
- Focuses on tasks that require external knowledge or specialized computations.
- Highlights the role of self-invocation and recursion in improving LLM performance.

# ACT: Augmenting Language Models with Actionable Tool Use (2022; Shridhar et al.) [arXiv:2212.10773](https://arxiv.org/abs/2212.10773)

- Introduces ACT, a framework that augments LLMs with actionable tool use.
- Combines reasoning with tool invocation to perform tasks like information retrieval and computation.
- Trains models to autonomously decide when and how to use tools during inference.
- Achieves significant gains in tasks that require external API interaction or environment manipulation.
- Emphasizes recursive reasoning and tool usage for solving complex queries.

# Code As Policies: Language Models as Zero-Shot Planners for Robots (2022; Li et al.) [arXiv:2110.14167](https://arxiv.org/abs/2110.14167)

- Explores using LLMs as zero-shot planners for robotic policies through code generation.
- Proposes the "Code as Policies" framework, translating language instructions into executable code for robots.
- Demonstrates the effectiveness of LLMs in planning and executing complex tasks without fine-tuning.
- Highlights recursive tool usage and decision-making processes for robots.
- Shows significant results in controlling robotic systems with natural language inputs.

# Recursive Tool Use in Language Models (2022; Jain et al.) [arXiv:2211.03225](https://arxiv.org/abs/2211.03225)

- Focuses on recursive tool use in LLMs to enhance reasoning and planning.
- Introduces a framework that enables LLMs to iteratively invoke tools to refine outputs.
- Demonstrates improvements in tasks requiring complex reasoning or multi-step processes.
- Explores recursive decision-making and tool usage in problem-solving.
- Highlights applications in scenarios like multi-step question answering and complex computations.

# PAL: Program-Aided Language Models (2022; Gao et al.) [arXiv:2205.01956](https://arxiv.org/abs/2205.01956)

- Proposes Program-Aided Language Models (PAL), integrating code generation and execution with language models.
- Demonstrates enhanced performance in tasks requiring procedural or algorithmic thinking.
- Introduces recursive execution, where the LLM generates and refines code iteratively.
- Focuses on tasks like math problem-solving and algorithmic reasoning with external code execution.
- Shows significant gains in logical and computational benchmarks through tool use.

# Tool-Use Transformer: Integrating APIs into Language Models for Enhanced Task Solving (2021; Shen et al.) [arXiv:2109.05747](https://arxiv.org/abs/2109.05747)

- Introduces the Tool-Use Transformer, a model designed to integrate API calls into LLM workflows.
- Focuses on tasks requiring external knowledge or operations, such as database queries and calculations.
- Uses transformer architecture to decide when and how to invoke tools for optimal performance.
- Highlights recursive reasoning and tool use for solving complex problems across domains.
- Demonstrates significant gains in tasks involving dynamic external resource use.

# Meta-LLM: Recursive Self-Improvement in Large Language Models (2021; Xu et al.) [arXiv:2103.08388](https://arxiv.org/abs/2103.08388)

- Presents Meta-LLM, a framework for recursive self-improvement in LLMs.
- Enables LLMs to learn from their outputs and refine future predictions.
- Emphasizes recursive tool invocation and self-correction to enhance model performance.
- Demonstrates success in iterative tasks like translation, reasoning, and decision-making.
- Focuses on recursive learning mechanisms to improve task-solving capabilities.

# Multi-Agent Collaboration with Language Models (2021; Hosseini et al.) [arXiv:2106.07126](https://arxiv.org/abs/2106.07126)

- Investigates multi-agent collaboration using LLMs for complex task-solving.
- Proposes a framework where multiple LLMs collaborate to invoke tools and complete tasks.
- Highlights the role of communication between agents for recursive decision-making.
- Demonstrates success in tasks like negotiation, problem-solving, and joint planning.
- Emphasizes tool use across agents to optimize overall task performance.

# Language Models as Tool Users (2020; Zellers et al.) [arXiv:2005.00782](https://arxiv.org/abs/2005.00782)

- Explores the concept of LLMs acting as tool users to solve complex tasks.
- Introduces a framework that allows LLMs to call external APIs for improved performance.
- Demonstrates that tool use enables LLMs to handle tasks beyond simple text generation.
- Shows success in domains like question answering, information retrieval, and arithmetic.
- Focuses on the integration of tool use into LLM workflows for enhanced reasoning.

# Tool-Assisted Reasoning with Language Models (2020; Wang et al.) [arXiv:2012.06595](https://arxiv.org/abs/2012.06595)

- Proposes a tool-assisted reasoning framework for LLMs.
- Focuses on improving LLM performance by integrating external tools for complex tasks.
- Demonstrates success in logical reasoning, arithmetic, and other tasks requiring specialized tools.
- Highlights the recursive invocation of tools to enhance problem-solving.
- Emphasizes the synergy between reasoning and tool use in achieving better outcomes.

# Few-Shot Learning with Language Models and Tool Use (2019; Brown et al.) [arXiv:1909.05858](https://arxiv.org/abs/1909.05858)

- Investigates few-shot learning in LLMs, incorporating external tool use.
- Demonstrates that tool use enhances few-shot learning performance across tasks.
- Shows significant improvements in tasks requiring specialized knowledge or operations.
- Emphasizes the role of tool invocation in extending LLM capabilities beyond text generation.
- Highlights the potential for recursive reasoning and decision-making in few-shot settings.

# Beyond Text: Using Language Models with External Tools (2019; Radford et al.) [arXiv:1904.01717](https://arxiv.org/abs/1904.01717)

- Explores the use of LLMs with external tools for tasks beyond text generation.
- Demonstrates that
